import torch
import gradio as gr
from PIL import Image
from accelerate.commands.config.update import description
from safetensors.torch import load_model
from transformers import (
    Blip2Processor,
    Blip2ForConditionalGeneration,
    LlavaForConditionalGeneration,
    AutoProcessor,
    BitsAndBytesConfig
)

class Config:
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    TORCH_DTYPE = torch.float16

    BLIP2_MODEL = "Salesforce/blip2-opt-2.7b"
    LLAVA_MODEL = "llava-hf/llava-1.5-7b-hf"

    USE_4BIT = True if DEVICE == "cuda" else False
    BNB_CONFIG = BitsAndBytesConfig(
        load_in_4bit=True,
        bnb_4bit_quant_type="nf4",
        bnb_4bit_compute_dtype=TORCH_DTYPE
    )

    MAX_NEW_TOKENS = 150
    TEMPERATURE = 0.7

    PROMPT_TEMPLATES = {
        "å°çº¢ä¹¦": (
            "ä½ æ˜¯ä¸€ä¸ªç¤¾äº¤åª’ä½“ä¸“å®¶ï¼Œè¯·ä¸ºä»¥ä¸‹å›¾ç‰‡ç”Ÿæˆä¸€æ¡é€‚åˆå°çº¢ä¹¦çš„å¸–å­: \n"
            "- ä½¿ç”¨2ä¸ªemoji\n"
            "- æ·»åŠ 3ä¸ªç›¸å…³è¯é¢˜æ ‡ç­¾\n"
            "- ä½¿ç”¨å£è¯­åŒ–çš„ä¸­æ–‡\n"
            "- åŒ…å«åœ°ç‚¹æˆ–å¿ƒæƒ…æè¿°\n"
            "- ç»“å°¾æå‡ºä¸€ä¸ªé—®é¢˜\n"
            "å›¾ç‰‡å†…å®¹: {description}"
        ),
        "Instagram": (
            "Generate an engaging Instagram post in English with: \n"
            "- 3 emojis\n"
            "- 4 hashtags\n"
            "- A question to encourage interaction\n"
            "Image content: {description}"
        )
    }

def load_models():
    blip_processor = Blip2Processor.from_pretrained(Config.BLIP2_MODEL)
    blip_model = Blip2ForConditionalGeneration.from_pretrained(
       Config.BLIP2_MODEL,
         torch_dtype=Config.TORCH_DTYPE,
         device_map=Config.DEVICE
    )

    llava_processor = AutoProcessor.from_pretrained(Config.LLAVA_MODEL)
    llava_model = LlavaForConditionalGeneration.from_pretrained(
        Config.LLAVA_MODEL,
        quantization_config=Config.BNB_CONFIG if Config.USE_4BIT else None,
        torch_dtype=Config.TORCH_DTYPE,
        device_map=Config.DEVICE
    )

    return blip_processor, blip_model, llava_processor, llava_model

def generate_social_post(image_path, platform):
    try:
        image = Image.open(image_path).convert("RGB")

        blip_processor, blip_model, llava_processor, llava_model = load_model()
        description = generate_image_description(blip_processor, blip_model, image)

        prompt_template = Config.PROMPT_TEMPLATES.get(platform, Config.PROMPT_TEMPLATES["å°çº¢ä¹¦"])
        prompt = prompt_template.format(description=description)

        inputs = llava_processor(
            text=prompt,
            image=image,
            return_tensors="pt"
        ).to(llava_model.device)

        outputs = llava_model.generate(
            **inputs,
            max_new_tokens=Config.MAX_NEW_TOKENS,
            temperature=Config.TEMPERATURE
        )

        return llava_processor.decode(outputs[0], skip_special_tokens=True).split("ASSISTANT:")[-1].strip()

    except Exception as e:
        return f"ç”Ÿæˆå¤±è´¥: {str(e)}"

def create_interface():
    with gr.Blocks(title="æ™ºèƒ½æ–‡æ¡ˆç”Ÿæˆå™¨", theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ğŸš€ æ™ºèƒ½ç¤¾äº¤åª’ä½“å†…å®¹ç”Ÿæˆå™¨")

        with gr.Row():
            with gr.Column():
                image_input = gr.Image(
                    type="filepath",
                    label="ä¸Šä¼ å›¾ç‰‡",
                    height=300
                )
                platform_selector = gr.Dropdown(
                    choices=["å°çº¢ä¹¦", "Instagram"],
                    value="å°çº¢ä¹¦",
                    label="é€‰æ‹©å¹³å°"
                )
                generate_bnt = gr.Button("ç”Ÿæˆæ–‡æ¡ˆ", variant="primary")

            output_text = gr.Textbox(
                label="ç”Ÿæˆç»“æœ",
                placeholder="æ–‡æ¡ˆå°†åœ¨è¿™é‡Œæ˜¾ç¤º...",
                lines=8,
                interactive=False
            )

        generate_bnt.click(
            fn=generate_social_post,
            inputs=[image_input, platform_selector],
            outputs=output_text
        )

    return demo

if __name__ == "__main__":
    print("æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")
    load_models()

    demo = create_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True
    )

